run ollama
start server
run python

-- DIT WERKT ALLEEN OP LINUX --


===========================================
ollama run bramvanroy/fietje-2b-chat:f16
===========================================
curl https://ollama.ai/install.sh | sh
ollama serve
===========================================
python llm_test.py

